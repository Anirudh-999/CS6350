{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1650695,"sourceType":"datasetVersion","datasetId":976194}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/anirudhrangu/cs6350?scriptVersionId=271827926\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# KITTI Dataset Visualization\n\nIn this step, we:\n1. **Load** stereo image pairs (left and right camera) from the KITTI dataset.\n2. **Read** the corresponding calibration text file to extract:\n   - The **rotation matrix (R)**\n   - The **translation vector (t)**\n3. **Display** a few sample images with their R and t values to confirm that data loading is correct.\n\nThis helps us ensure that the image data and ground-truth poses are aligned before moving into keypoint detection and pose estimation.\n","metadata":{}},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom mpl_toolkits.mplot3d import Axes3D","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-28T18:15:14.467Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_dir = \"/kaggle/input/kitti-dataset\"  \nleft_dir = os.path.join(base_dir, \"data_object_image_2/training/image_2/000000.png\")  # left camera images\npose_file = os.path.join(base_dir, \"data_object_label_2/training/label_2/000000.txt\")  # pose file","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-28T18:15:14.468Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndef parse_kitti_label_file(label_path):\n\n    columns = [\n        \"type\", \"truncated\", \"occluded\", \"alpha\",\n        \"bbox_xmin\", \"bbox_ymin\", \"bbox_xmax\", \"bbox_ymax\",\n        \"height\", \"width\", \"length\",\n        \"pos_x\", \"pos_y\", \"pos_z\",\n        \"rotation_y\"\n    ]\n    \n    data = []\n\n    try:\n        with open(label_path, 'r') as f:\n            for line in f:\n                parts = line.strip().split()\n                if parts[0] == \"DontCare\":\n                    continue  # skip non-labeled regions\n                values = parts[:15]  # ensure only 15 fields are taken\n                data.append(values)\n        \n        # Convert to DataFrame\n        df = pd.DataFrame(data, columns=columns)\n        \n        # Convert numeric columns to float\n        for col in columns[1:]:\n            df[col] = df[col].astype(float)\n        \n        return df\n    except:\n        with exception as e:\n            print(\"error:\", e)\n\n# Example usage:\nlabel_file = \"/kaggle/input/kitti-dataset/data_object_label_2/training/label_2/000001.txt\"\ndf = parse_kitti_label_file(label_file)\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-28T18:15:14.468Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading KITTI Stereo Images, Labels, and Calibration Data\n\nThe KITTI dataset includes:\n- Left image: for stereo, used as reference image\n- Right image: corresponding stereo pair\n- Calibration file: contains camera projection matrices for the stereo cameras\n- Label file: includes ground-truth 2D/3D bounding boxes, object dimensions, and location\n\nThis code dynamically reads all these files for the first image and prints relevant information for visualization and understanding.\n","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Base directory for KITTI dataset on Kaggle\nKITTI_BASE = '/kaggle/input/kitti-dataset'\n\n# Define relative paths (dynamic)\nRIGHT_IMG_DIR = os.path.join(KITTI_BASE, 'data_object_image_2', 'training', 'image_2')\nLEFT_IMG_DIR = os.path.join(KITTI_BASE, 'data_object_image_3', 'training', 'image_3')\nCALIB_DIR = os.path.join(KITTI_BASE, 'data_object_calib', 'training', 'calib')\nLABEL_DIR = os.path.join(KITTI_BASE, 'data_object_label_2', 'training', 'label_2')\n\n# Function to load calibration projection matrices from calib file\ndef load_calibration(file_path):\n    calib_data = {}\n    with open(file_path, 'r') as f:\n        lines = f.readlines()\n        for line in lines:\n            key, value = line.split(':', 1)\n            values = np.array([float(v) for v in value.split()])\n            if key.startswith('R') and values.size == 9:  # Rectification matrix 3x3\n                calib_data[key] = values.reshape(3, 3)\n            elif values.size == 12:  # Projection matrix 3x4\n                calib_data[key] = values.reshape(3, 4)\n            else:\n                calib_data[key] = values  # Any other numeric data remains raw for now\n    return calib_data\n\n\n# Load first frame index\nimg_id = '000000'\n\n# Load stereo images\nright_img_path = os.path.join(RIGHT_IMG_DIR, f'{img_id}.png')\nleft_img_path = os.path.join(LEFT_IMG_DIR, f'{img_id}.png')\n\nright_img = cv2.cvtColor(cv2.imread(right_img_path), cv2.COLOR_BGR2RGB)\nleft_img = cv2.cvtColor(cv2.imread(left_img_path), cv2.COLOR_BGR2RGB)\n\n# Load calibration data\ncalib_path = os.path.join(CALIB_DIR, f'{img_id}.txt')\ncalib = load_calibration(calib_path)\n\n# Load labels\nlabel_path = os.path.join(LABEL_DIR, f'{img_id}.txt')\nwith open(label_path, 'r') as f:\n    labels = f.readlines()\n\n# Display left and right stereo images\nplt.figure(figsize=(12,6))\nplt.subplot(1,2,1)\nplt.imshow(left_img)\nplt.title('Left Image (image_3)')\nplt.axis('off')\n\nplt.subplot(1,2,2)\nplt.imshow(right_img)\nplt.title('Right Image (image_2)')\nplt.axis('off')\nplt.show()\n\n# Print Projection matrices from calibration\nprint(\"Camera Projection Matrices (P2 - right camera, P3 - left camera):\")\nfor key in ['P2', 'P3']:\n    if key in calib:\n        print(f\"\\n{key} matrix:\\n{calib[key]}\")\n\n# Parse and print label info for visualization\nprint(\"\\nDetected Objects and their Labels:\")\nfor line in labels:\n    parts = line.strip().split(' ')\n    class_name = parts[0]\n    truncation = float(parts[1])\n    occlusion = int(parts[2])\n    alpha = float(parts[3])\n    bbox = list(map(float, parts[4:8]))\n    dimensions = list(map(float, parts[8:11]))\n    location = list(map(float, parts[11:14]))\n    rotation_y = float(parts[14])\n\n    print(f\"\\nClass: {class_name}\")\n    print(f\"Truncation: {truncation}, Occlusion: {occlusion}, Alpha: {alpha}\")\n    print(f\"2D Bounding Box: {bbox}\")\n    print(f\"3D Dimensions (h,w,l): {dimensions}\")\n    print(f\"3D Location (x,y,z): {location}\")\n    print(f\"Rotation Y (radians): {rotation_y}\")\n\n    # Draw bounding box on left image for visualization\n    cv2.rectangle(left_img, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (255, 0, 0), 2)\n    cv2.putText(left_img, class_name, (int(bbox[0]), int(bbox[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n\n# Show left image with bounding boxes drawn\nplt.figure(figsize=(10,6))\nplt.imshow(left_img)\nplt.title(\"Left Image with Ground Truth Bounding Boxes\")\nplt.axis('off')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T14:05:23.006894Z","iopub.execute_input":"2025-10-29T14:05:23.007978Z","iopub.status.idle":"2025-10-29T14:05:23.089019Z","shell.execute_reply.started":"2025-10-29T14:05:23.007939Z","shell.execute_reply":"2025-10-29T14:05:23.087814Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/1117461614.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Load calibration data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mcalib_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCALIB_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{img_id}.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mcalib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_calibration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalib_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Load labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_37/1117461614.py\u001b[0m in \u001b[0;36mload_calibration\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'R'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Rectification matrix 3x3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"],"ename":"ValueError","evalue":"not enough values to unpack (expected 2, got 1)","output_type":"error"}],"execution_count":2}]}